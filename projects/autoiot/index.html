<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="AutoIOT: LLM-Driven Automated Natural Language Programming for AIoT Applications">
    <meta name="keywords" content="AutoIOT">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>AutoIOT: LLM-Driven Automated Natural Language Programming for AIoT Applications</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="/assets/static/css/bulma.min.css">
    <link rel="stylesheet" href="/assets/static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="/assets/static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="/assets/static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="/assets/static/css/index.css">
    <link rel="icon" href="/assets/static/images/favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="/assets/static/js/fontawesome.all.min.js"></script>
    <script src="/assets/static/js/bulma-carousel.min.js"></script>
    <script src="/assets/static/js/bulma-slider.min.js"></script>
    <script src="/assets/static/js/index.js"></script>
    <script type="text/javascript" src="/assets/static/js/MathJax.js"></script>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">AutoIOT: LLM-Driven Automated Natural Language Programming for AIoT Applications</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
              <a href="https://lemingshen.github.io/" target="_blank">Leming Shen</a><sup>1</sup>,</span>
                            <span class="author-block">
              <a href="https://www.cl.cam.ac.uk/~qy258/" target="_blank">Qiang Yang</a><sup>2</sup>,</span>
                            <span class="author-block">
              <a href="https://www4.comp.polyu.edu.hk/~csyqzheng/" target="_blank">Yuanqing Zheng</a><sup>1</sup>,
            </span>
                            <span class="author-block">
              <a href="https://home.cse.ust.hk/~lim/" target="_blank">Mo Li</a><sup>3</sup>,
            </span>
            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>The Hong Kong Polytechnic University,</span>
                            <span class="author-block"><sup>2</sup>University of Cambridge,</span>
                            <span class="author-block"><sup>3</sup> Hong Kong University of Science and Technology</span>
                        </div>

                        <div class="column has-text-centered">

                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="https://lemingshen.github.io/assets/publication/conference/AutoIOT/paper.pdf" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                <span>Paper</span>
                                </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://github.com/lemingshen/AutoIOT" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                <span>Code</span>
                                </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://mypikpak.com/s/VOLO45qfpLUd1wEMUhhhoJCyo1" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-images fa-w-18" aria-hidden="true" focusable="false" data-prefix="far" data-icon="images" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" data-fa-i2svg="" width="80px"><path fill="currentColor" d="M480 416v16c0 26.51-21.49 48-48 48H48c-26.51 0-48-21.49-48-48V176c0-26.51 21.49-48 48-48h16v48H54a6 6 0 0 0-6 6v244a6 6 0 0 0 6 6h372a6 6 0 0 0 6-6v-10h48zm42-336H150a6 6 0 0 0-6 6v244a6 6 0 0 0 6 6h372a6 6 0 0 0 6-6V86a6 6 0 0 0-6-6zm6-48c26.51 0 48 21.49 48 48v256c0 26.51-21.49 48-48 48H144c-26.51 0-48-21.49-48-48V80c0-26.51 21.49-48 48-48h384zM264 144c0 22.091-17.909 40-40 40s-40-17.909-40-40 17.909-40 40-40 40 17.909 40 40zm-72 96l39.515-39.515c4.686-4.686 12.284-4.686 16.971 0L288 240l103.515-103.515c4.686-4.686 12.284-4.686 16.971 0L480 208v80H192v-48z"></path></svg><!-- <i class="far fa-images"></i> Font Awesome fontawesome.com -->
                  </span>
                                <span>Data</span>
                                </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://youtu.be/E0INJT9xEWg" target="_blank" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-images fa-w-18" aria-hidden="true" focusable="false" data-prefix="far" data-icon="images" role="img" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" width="80px"><g id="SVGRepo_bgCarrier" stroke-width="0"></g><g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g><g id="SVGRepo_iconCarrier"> <path fill-rule="evenodd" clip-rule="evenodd" d="M9.49614 7.13176C9.18664 6.9549 8.80639 6.95617 8.49807 7.13509C8.18976 7.31401 8 7.64353 8 8V16C8 16.3565 8.18976 16.686 8.49807 16.8649C8.80639 17.0438 9.18664 17.0451 9.49614 16.8682L16.4961 12.8682C16.8077 12.6902 17 12.3589 17 12C17 11.6411 16.8077 11.3098 16.4961 11.1318L9.49614 7.13176ZM13.9844 12L10 14.2768V9.72318L13.9844 12Z" fill="#0F0F0F"></path> <path fill-rule="evenodd" clip-rule="evenodd" d="M0 12C0 8.25027 0 6.3754 0.954915 5.06107C1.26331 4.6366 1.6366 4.26331 2.06107 3.95491C3.3754 3 5.25027 3 9 3H15C18.7497 3 20.6246 3 21.9389 3.95491C22.3634 4.26331 22.7367 4.6366 23.0451 5.06107C24 6.3754 24 8.25027 24 12C24 15.7497 24 17.6246 23.0451 18.9389C22.7367 19.3634 22.3634 19.7367 21.9389 20.0451C20.6246 21 18.7497 21 15 21H9C5.25027 21 3.3754 21 2.06107 20.0451C1.6366 19.7367 1.26331 19.3634 0.954915 18.9389C0 17.6246 0 15.7497 0 12ZM9 5H15C16.9194 5 18.1983 5.00275 19.1673 5.10773C20.0989 5.20866 20.504 5.38448 20.7634 5.57295C21.018 5.75799 21.242 5.98196 21.4271 6.23664C21.6155 6.49605 21.7913 6.90113 21.8923 7.83269C21.9973 8.80167 22 10.0806 22 12C22 13.9194 21.9973 15.1983 21.8923 16.1673C21.7913 17.0989 21.6155 17.504 21.4271 17.7634C21.242 18.018 21.018 18.242 20.7634 18.4271C20.504 18.6155 20.0989 18.7913 19.1673 18.8923C18.1983 18.9973 16.9194 19 15 19H9C7.08058 19 5.80167 18.9973 4.83269 18.8923C3.90113 18.7913 3.49605 18.6155 3.23664 18.4271C2.98196 18.242 2.75799 18.018 2.57295 17.7634C2.38448 17.504 2.20866 17.0989 2.10773 16.1673C2.00275 15.1983 2 13.9194 2 12C2 10.0806 2.00275 8.80167 2.10773 7.83269C2.20866 6.90113 2.38448 6.49605 2.57295 6.23664C2.75799 5.98196 2.98196 5.75799 3.23664 5.57295C3.49605 5.38448 3.90113 5.20866 4.83269 5.10773C5.80167 5.00275 7.08058 5 9 5Z" fill="#0F0F0F"></path> </g></svg>
                  </span>
                                <span>Demo Video</span>
                                </a>
                                </span>
                            </div>
                            <!-- <div class="publication-links">
                                <span class="link-block">
                                <p class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <img src="../../images/available.png" width="25px">
                                    </span>
                                <span>Artifacts Available</span>
                                </p>
                                </span>
                                <span class="link-block">
                                <p class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <img src="../../images/functional.png" width="25px">
                                    </span>
                                <span>Artifacts Evaluated Functional</span>
                                </p>
                                </span>
                                <span class="link-block">
                                <p class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <img src="../../images/reusable.png" width="25px">
                                    </span>
                                <span>Artifacts Evaluated Reusable</span>
                                </p>
                                </span>
                            </div> -->
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop is-centered content">
            <img src="./assets/system_overview.jpg" />
            <h5 class="subtitle has-text-centered">
                The architecture of <span class="dnerf">AutoIOT</span>
            </h5>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            The advent of Large Language Models (LLMs) has profoundly transformed our lives, revolutionizing interactions with AI and lowering the barrier to AI usage. While LLMs are primarily designed for natural language interaction, the extensive embedded knowledge empowers them to comprehend digital sensor data. This capability enables LLMs to engage with the physical world through IoT sensors and actuators, performing a myriad of AIoT tasks. Consequently, this evolution triggers a paradigm shift in conventional AIoT application development, democratizing its accessibility to all by facilitating the design and development of AIoT applications via natural language. However, some limitations need to be addressed to unlock the full potential of LLMs in AIoT application development. First, existing solutions often require transferring raw sensor data to LLM servers, which raises privacy concerns, incurs high query fees, and is limited by token size. Moreover, the reasoning processes of LLMs are opaque to users, making it difficult to verify the robustness and correctness of inference results. This paper introduces AutoIOT, an LLM-based automated program generator for AIoT applications. AutoIOT enables users to specify their requirements using natural language (input) and automatically synthesizes interpretable programs with documentation (output). AutoIOT automates the iterative optimization to enhance the quality of generated code with minimum user involvement. AutoIOT not only makes the execution of AIoT tasks more explainable but also mitigates privacy concerns and reduces token costs with local execution of synthesized programs. Extensive experiments and user studies demonstrate AutoIOT's remarkable capability in program synthesis for various AIoT tasks. The synthesized programs can match and even outperform some representative baselines.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Introduction. -->
            <div class="columns">
                <div class="column is-full-width">
                    <h2 class="title is-3">Introduction</h2>
                    <div class="content has-text-justified">
                        <p>
                            Recent advances in large language models (LLMs) (e.g., GPT-4) fundamentally changed the way we interact with AI. While initially designed to understand natural languages, recent pioneering works have demonstrated considerable proficiency of LLMs in exploiting embedded world knowledge by interpreting IoT sensor data to perform various AIoT tasks. Recent works term such an endeavor – Penetrative AI. Fig. 1 illustrates how LLMs can be tasked to comprehend and even interact with the physical world through integration with IoT sensors and actuators.
                        </p>
                        <div class="content has-text-centered">
                            <img src="./assets/blueprint.jpg" width="50%" />
                        </div>
                        <h6 class="subtitle has-text-centered">Figure 1: Illustration of how LLMs can sense and interact with the physical world in AIoT applications.</h6>
                        <p>
                            <strong>However, current LLMs on AIoT tasks fall short in supporting AIoT applications:</strong>
                            <ul>
                                <li>
                                    The <strong>trustworthiness</strong> of the inference results is compromised since the inference process is performed inside a "black box" and opaque to users. Thus, the robustness of the applications or the correctness of the inference results are hard to verify.
                                </li>
                                <li>
                                    Transmitting the raw or intermediate sensor data from user devices to LLM servers raises <strong>privacy concerns</strong>, incurs prohibitive query fees, and increases response latency.
                                </li>
                                <li>
                                    Sensor data typically exhibits <strong>extensive length and high dimensionality</strong>, making remote processing at LLM servers infeasible due to token limits. 
                                </li>
                            </ul>
                            <strong>Ideally, the integration of LLMs with AIoT applications should be trustworthy, privacy-preserving, and communication-efficient.</strong>
                        </p>
                        <h3 style="color:red"><i>Can we leverage LLMs to synthesize programs to automatically fulfill AIoT application requirements?</i></h3>
                        <p>
                            This approach can 
                            <ul>
                                <li>
                                    <strong>Enhance the explainability and trustworthiness</strong> of the AIoT applications as the synthesized programs can be examined and interpreted by developers.
                                </li>
                                <li>
                                    <strong>Mitigate privacy concerns, and reduce the communication cost</strong> since the programs can be executed locally on user devices without offloading raw sensor data.
                                </li>
                                <li>
                                    <strong>Efficiently process high-dimensional continuous sensor data</strong> without being limited by the token size or bounded by the round trip time over the network.
                                </li>
                            </ul>
                            To this end, we propose AutoIOT, a user-friendly natural language programming system based on LLMs. AutoIOT automatically identifies and retrieves the necessary domain knowledge over the Internet, intelligently synthesizes programs, and evolves the programs iteratively given sample inputs and ground truth. <strong>Surprisingly, we found that the synthesized programs can sometimes outperform some representative baselines and sample programs of recent academic papers.</strong>
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Introduction. -->
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Motivation. -->
            <div class="columns">
                <div class="column is-full-width">
                    <h2 class="title is-3">Motivation</h2>
                    <div class="content has-text-justified">
                        <p>
                            The latest LLMs have demonstrated extraordinary proficiency in generating code snippets. For example, Mercury leverages LLMs to generate code for well-defined programming tasks. <strong>Is it feasible to instruct LLMs to synthesize programs that can tackle AIoT tasks? Our preliminary results show that it is possible yet extremely challenging for LLMs to synthesize functionally correct programs for AIoT tasks.</strong> Taking heartbeat detection as an example, as depicted in Fig. 2. When we instruct the LLM to generate a program to process raw ECG waveform and detect heartbeats, the LLM can only generate a few null functions without concrete implementation or import some nonexistent packages.
                        </p>
                        <div class="content has-text-centered">
                            <img src="./assets/direct_code_generation.jpg" width="45%" />
                        </div>
                        <h6 class="subtitle has-text-centered">Figure 2: An example of direct code generation.</h6>
                        <p>
                            To fill this gap, we develop an LLM-driven automated natural language programming system named AutoIOT to three key modules:
                            <ul>
                                <li>
                                    <strong>Background knowledge retrieval</strong> module that automatically collects domain knowledge from the Internet for in-context learning.
                                </li>
                                <li>
                                    <strong>Automated program synthesis</strong> module that emulates the program development lifecycle via CoT prompting. This module decomposes an AIoT task into several subtasks and generates corresponding functional code snippets.
                                </li>
                                <li>
                                    <strong>Code improvement</strong> module that executes the synthesized program and feeds the compiler and interpreter feedback to the LLM, facilitating iterative code correction and improvement
                                </li>
                            </ul>
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Motivation. -->
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- overview. -->
            <div class="columns">
                <div class="column is-full-width">
                    <h2 class="title is-3">System Overview</h2>
                    <div class="content has-text-justified">
                        <p>
                            Fig. 3 illustrates the architecture of <span class="dnerf">AutoIOT</span>, consisting of three main modules: <i>background knowledge retrieval</i>, <i>automated program synthesis</i>, and <i>code improvement</i>.
                        </p>
                        <p>
                            Users can specify their requirements on AIoT applications in natural language (①). Then, the background knowledge retrieval module identifies a set of relevant terminologies (②) and searches over the Internet (③). With the retrieved domain-specific knowledge, the automated program synthesis module instructs the agent to draft an algorithm outline (④). The agent is then requested to elaborate on each step of the algorithm and produce a detailed design (⑤). Such a process decomposes a complex AIoT task into several manageable subtasks. Then, the agent is instructed to generate a code segment for each subtask (⑥). Afterward, the agent is requested to integrate the codes for subtasks and synthesize the final program (⑦). Next, the code self-improvement module executes the synthesized program and feeds the compiler and interpreter output back to the agent. The agent iteratively corrects syntax and semantics errors (⑧). With the obtained output from the synthesized program, AutoIOT explicitly instructs the agent to explore more advanced algorithms using the web search tool, aiming to optimize the program and improve the performance of inference tasks (⑨). After several iterations (④-⑨), AutoIOT will present the final program with detailed documentation (⑩). In addition, AutoIOT provides an interface for users to offer specific algorithms or instructions for code improvement.
                        </p>
                        <div class="content has-text-centered">
                            <img src="./assets/system_overview.jpg" />
                        </div>
                        <h6 class="subtitle has-text-centered">Figure 3: System overview.</h6>
                    </div>
                </div>
            </div>
            <!--/ Overview. -->
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Evaluation. -->
            <div class="columns">
                <div class="column is-full-width">
                    <h2 class="title is-3">Evaluation</h2>
                    <div class="content has-text-justified">
                        <p>
                            We evaluate the overall performance of <span class="dnerf">AutoIOT</span> on four representative AIoT applications.
                        </p>

                        <div class="content has-text-centered">
                            <img src="./assets/overall_performance.jpg" />
                        </div>
                        <h6 class="subtitle has-text-centered">Figure 4: Figure 10: The overall performance of the four IoT applications. In (a), A. for AutoIOT, H. for Hamiltion, C. for Christov, E. for Engzee, P. for Pan-Tompkins, and S. for SWT. In (b), N. for NN, 1D for 1D-CNN, Bi. for BiLSTM, C. for Conv-LSTM, L. for LSTM-RNN, and 𝒏 for ResNet-𝒏. In (c) & (d), A.1, A.2, and A.3 for three different AutoIOT - generated programs; B. for the baseline in the multimodal HAR application.</h6>
                    </div>
                    
                    <div class="content has-text-justified">
                        <h3 class="title is-4">1. Heartbeat Detection <a href="./main_ECG.html" target="_blank">Demo</a></h3>
                        <p>
                            Fig. 4(a) shows the heartbeat detection accuracy with MAE of AutoIOT (denoted as A.) and baselines. First of all, AutoIOT can synthesize a program automatically to achieve comparable performance with baselines in the heartbeat detection task. More surprisingly, the automatically synthesized program can even beat some of the baselines! For example, the synthesized program achieves higher detection accuracy than Pan-Tompkins (P.) and Engzee (E.). Moreover, it yields a lower error rate than Christov (C.) and Pan-Tompkins (P.). To investigate the reasons behind this, we examine and analyze the synthesized program.
                        </p>
                    </div>
                    
                    <div class="content has-text-justified">
                        <h3 class="title is-4">2. IMU-based & mmWave-based Human Activity Recognition (HAR) <a href="./main_IMU.html" target="_blank">Demo 1</a> <a href="./main_mmWave.html" target="_blank">Demo 2</a></h3>
                        <p>
                            Fig. 4(b) shows the classification accuracy in two HAR tasks. We observe that AutoIOT outperforms NN and 1DCNN while underperforms BiLSTM, Conv-LSTM and LSTMRNN. The main reasons are twofold: (1) HAR tasks require both signal processing and machine learning algorithms, increasing the programming complexity to some extent; (2) Training neural networks requires fine-tuning of a vast array of hyper-parameters (e.g., network architecture configurations, epoch number, learning rate, optimizer, and loss function). This significantly amplifies the instability of the generated code and calls for careful fine-tuning to achieve the best performance in practice. As a result, AutoIOT surpasses those baselines adopting simple model architectures (NN and one-dimensional CNN) but falls short against baselines using sophisticated architectures (BiLSTM and Conv-LSTM) with highly optimized hyper-parameters. Although during code improvement, some synthesized programs define a set of configurations and adopt a searching strategy to obtain optimal hyper-parameters, the performance still remains slightly lower than some baselines. This is because the determination of the optimal configurations for machine learning models is typically a trial-and-error process, requiring substantial human effort. Fortunately, we observe that if the user provides a potential search space in advance, the LLM can design a search algorithm to try different hyper-parameter configurations and select the one with the best performance.
                        </p>
                    </div>

                    <div class="content has-text-justified">
                        <h3 class="title is-4">3. Multimodal HAR <a href="./main_multimodal.html" target="_blank">Demo</a></h3>
                        <p>
                            For multimodal HAR, the input instruction (A1) includes the basic information of the task, i.e., the task target, the dataset specifications, and the output format. Based on that, we create two additional variations: one with a GPUmemory-constrained requirement (A2) and another with a high accuracy requirement (A3). We then feed the instructions into AutoIOT and measure the accuracy and inference time of the synthesized programs, with results shown in Fig. 4(c). By analyzing the three synthesized different programs, we observe that: (1) All the synthesized programs adopt a similar workflow as the baseline system, i.e., they first construct three encoders to extract effective features from the three modalities, then concatenate these features and feed them into a classifier for activity recognition. This implies that benefiting from our CoT-based problem-solving paradigm, AutoIOT recognizes the workflow and architecture as effective and standard for handling multimodal data-related tasks, which is consistent with most of the existing methods. (2) AutoIOT can adjust the generated code to fulfill different requirements. The second program consumes less memory than others due to the resource constraint requirement, resulting in lower accuracy but reduced inference time (Fig. 4(d)). On the other hand, the third program adopts a more complex and larger model architecture, requiring more GPU memory and incurring a longer inference time. Such differences validate the capabilities of AutoIOT in accurately understanding and processing natural language-based user requirements. These observations further demonstrate the effectiveness of AutoIOT in ensuring the correctness of user requirement understanding and the generated code, benefiting from our automatic self-improvement component.
                        </p>
                    </div>
                    
                    <div class="content has-text-justified">
                        <h3 class="title is-4">4. User Study</h3>
                        <p>
                            To investigate the utilities of AutoIOT, we conduct a user study (N=20) by inviting 5 expert and 15 non-expert users. The expert users are PhD students and professors with work or research experience in the IoT field and have developed many IoT applications. We select human activity recognition using RFID data (XRF55 dataset [ 73]) as the IoT application, where a 1D Conv-based ResNet18 is the baseline.
                        </p>
                        <div class="content has-text-centered">
                            <img src="./assets/objective.jpg" width="60%"/>
                        </div>
                        <h6 class="subtitle has-text-centered">Figure 5: User study (Objective Evaluation).</h6>
                        <ul>
                            <li>
                                <strong>Objective Evaluation</strong> We first repeatedly measure the average task accuracy (classification accuracy) after executing the synthesized programs, with the results shown in Fig. 5(a).
                            </li>
                            <li>
                                <strong>Subjective Evaluation</strong> We ask the users to execute the synthesized programs and rate AutoIOT based on four subjective metrics: 
                                <ul>
                                    <li>
                                        <strong>System Utility (SU)</strong> measures the user's overall satisfaction with AutoIOT's performance.
                                    </li>
                                    <li>
                                        <strong>Requirement Coverage (RC)</strong> evaluates how well the user requirements are fulfilled by AutoIOT.
                                    </li>
                                    <li>
                                        <strong>Code & Documentation Readability (CDR)</strong> measures the clarity and structure of the code and documentation.
                                    </li>
                                    <li>
                                        <strong>Generation Efficiency (GE)</strong> accesses how acceptable the waiting time is for synthesizing the final program.
                                    </li>
                                </ul>
                                All the above metrics are rated by the users on a scale from 1 (not at all) to 6 (more than expected). The results are shown in shown in Fig. 6.
                            </li>
                        </ul>

                        <div class="content has-text-centered">
                            <img src="./assets/subjective.jpg" width="20%"/>
                        </div>
                        <h6 class="subtitle has-text-centered">Figure 6: User study (Subjective Evaluation).</h6>
                    </div>
                </div>
            </div>
            <!--/ Evaluation. -->
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Conclusion. -->
            <div class="columns">
                <div class="column is-full-width">
                    <h2 class="title is-3">Conclusion</h2>
                    <div class="content has-text-justified">
                        <p>
                            We propose AutoIOT, an LLM-driven automated natural language programming system for AIoT applications. Our system features three novel technical modules: <i>background knowledge retrieval</i>, <i>automated program synthesis</i>, and <i>code improvement</i>, transforming natural language descriptions into executable programs. Our experiments demonstrate the competitive performance of AutoIOT in synthesizing programs for a variety of AIoT applications, with comparable performance in challenging AIoT tasks and sometimes outperforming some representative baselines. This showcases the strong potential of exploiting the embedded common knowledge of LLMs to evolve AIoT application development.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Conclusion. -->
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <p>
                <svg class="svg-inline--fa fa-hand-point-right fa-w-16" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="hand-point-right" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg="" width="80px"><path fill="currentColor" d="M512 199.652c0 23.625-20.65 43.826-44.8 43.826h-99.851c16.34 17.048 18.346 49.766-6.299 70.944 14.288 22.829 2.147 53.017-16.45 62.315C353.574 425.878 322.654 448 272 448c-2.746 0-13.276-.203-16-.195-61.971.168-76.894-31.065-123.731-38.315C120.596 407.683 112 397.599 112 385.786V214.261l.002-.001c.011-18.366 10.607-35.889 28.464-43.845 28.886-12.994 95.413-49.038 107.534-77.323 7.797-18.194 21.384-29.084 40-29.092 34.222-.014 57.752 35.098 44.119 66.908-3.583 8.359-8.312 16.67-14.153 24.918H467.2c23.45 0 44.8 20.543 44.8 43.826zM96 200v192c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V200c0-13.255 10.745-24 24-24h48c13.255 0 24 10.745 24 24zM68 368c0-11.046-8.954-20-20-20s-20 8.954-20 20 8.954 20 20 20 20-8.954 20-20z"></path></svg>                For more details, please refer to our <a href="https://lemingshen.github.io/assets/publication/conference/AutoIOT/paper.pdf" target="_blank"><svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg="" width="80px"><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->Paper</a>.
            </p>
            <p>
                <svg class="svg-inline--fa fa-hand-point-right fa-w-16" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="hand-point-right" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg="" width="80px"><path fill="currentColor" d="M512 199.652c0 23.625-20.65 43.826-44.8 43.826h-99.851c16.34 17.048 18.346 49.766-6.299 70.944 14.288 22.829 2.147 53.017-16.45 62.315C353.574 425.878 322.654 448 272 448c-2.746 0-13.276-.203-16-.195-61.971.168-76.894-31.065-123.731-38.315C120.596 407.683 112 397.599 112 385.786V214.261l.002-.001c.011-18.366 10.607-35.889 28.464-43.845 28.886-12.994 95.413-49.038 107.534-77.323 7.797-18.194 21.384-29.084 40-29.092 34.222-.014 57.752 35.098 44.119 66.908-3.583 8.359-8.312 16.67-14.153 24.918H467.2c23.45 0 44.8 20.543 44.8 43.826zM96 200v192c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V200c0-13.255 10.745-24 24-24h48c13.255 0 24 10.745 24 24zM68 368c0-11.046-8.954-20-20-20s-20 8.954-20 20 8.954 20 20 20 20-8.954 20-20z"></path></svg>                The code for implementing <span class="dnerf">AutoIOT</span> is available at <a href="https://github.com/lemingshen/AutoIOT" target="_blank"><svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg="" width="80px"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->here</a>.
            </p>
        </div>
        <section <section class="section" id="BibTeX">
            <div class="container is-max-desktop content">
                <h2 class="title">BibTeX</h2>
                <pre><code>@inproceedings{shen2025autoiot,
  title={AutoIOT: LLM-Driven Automated Natural Language Programming for AIoT Applications},
  author={Shen, Leming and Yang, Qiang and Zheng, Yuanqing and Li, Mo},
  booktitle={Proceedings of the 31st Annual International Conference on Mobile Computing and Networking},
  pages={1--15},
  year={2025}
}</code></pre>
            </div>
        </section>


        <footer class="footer">
            <div class="columns is-centered">
                <div class="content">
                    <p>Website template borrowed from <a rel="license" href="https://nerfies.github.io/">NeRFies</a>.</p>
                </div>
            </div>
            </div>
        </footer>

</body>

</html>